{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob, os\n",
    "import fileinput\n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read files\n",
    "data_dir = \"data\"\n",
    "timelines_dir = \"%s/timelines\" % data_dir\n",
    "test_dir = \"%s/test1\" % timelines_dir\n",
    "\n",
    "\n",
    "#data = open(\"data/timelines/test1/63299591\",\"r\")\n",
    "#data = open(\"data/timelines/test1/3578166252\",\"r\")\n",
    "#data = \"data/timelines/test1/3578166252\"\n",
    "data_file = \"%s/133684052\" % test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entry_check(tweet,collection_data):\n",
    "    # tweet is a variable for the full_text in the raw_file\n",
    "    # collection_data is the file with the manipulated full_text for collection\n",
    "    rawfile = open(collection_data,'r')\n",
    "    for lines in rawfile:\n",
    "        #print(lines)\n",
    "        if tweet+\"\\n\" == lines:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_data_collect(rawdata,collection):\n",
    "    with open(rawdata,\"r\") as data:\n",
    "        for lines in data:\n",
    "\n",
    "            #ToDo\n",
    "            #Remove all links, @usernames\n",
    "\n",
    "            # remove empty spaces and unwanted line breaks\n",
    "            json_lines = json.loads(lines)\n",
    "            tweet = json_lines[\"full_text\"]\n",
    "            tweet = tweet.replace(\"\\n\",\"\")\n",
    "            tweet = tweet.replace(\"\\r\",\"\")\n",
    "            tweet = re.sub('@[^\\s]+','',tweet)       # removes all the usernames\n",
    "            tweet = re.sub(r\"http\\S+\", \"\", tweet)    # removes all the links\n",
    "\n",
    "            # check whether tweet is japanese\n",
    "            if detect(tweet) != \"ja\":\n",
    "                #lang = detect(tweet)\n",
    "                #print(lang)\n",
    "                print(tweet)\n",
    "                continue\n",
    "\n",
    "            # exclude sentences shorter than 5 characters\n",
    "            elif len(tweet) < 5:\n",
    "                print(\"deleted: \",tweet)\n",
    "                continue\n",
    "            else:\n",
    "                f = open(collection,\"a\")\n",
    "                if entry_check(tweet,collection) == True:\n",
    "                    continue\n",
    "                f.write(tweet+\"\\n\")\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_iterator(aim_file):\n",
    "    todo_path = os.path.join(os.getcwd(), \"data\", \"timelines\")\n",
    "    #todo_path_current = os.getcwd()\n",
    "\n",
    "    #ROOT = [os.path.join(todo_path, filename) for filename in filter(os.path.isdir, os.listdir(todo_path))]\n",
    "\n",
    "    ROOT = [os.path.join(todo_path, filename) for filename in os.listdir(todo_path)]\n",
    "\n",
    "\n",
    "    for x in ROOT:\n",
    "        if os.path.isdir(x):\n",
    "            for item in os.listdir(x):\n",
    "                print(item)\n",
    "                data = os.path.join(x, item)\n",
    "                #print(data)\n",
    "                raw_data_collect(data,aim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3578166252\n",
      "133684052\n",
      "63299591\n",
      "93196638\n",
      "豆乳を投入(=ﾟωﾟ)ﾉ。RT  豆乳を投入(=ﾟωﾟ)ﾉ　　#豆乳を投入\n",
      "RT  HELLO, DOLLY !The NEW Broadway Cast Recordingはてなブログに投稿しました #はてなブログRCA Records ANL1-2849 - ひとりDiscogs\n",
      "RT  Cyril Mokaiesh &amp; Bernard Lavilliers - La loi du marché (2016)  新自由主義者に好き放題をされている現代世界について歌う「市場の法則」…\n",
      "RT  はてなブログに投稿しました #はてなブログ1938.02.17. SLIM and SLAM [SLIM GAILLARD 2nd session] - ...years ago today\n",
      "RT  Sonny Clay's Plantation Orchestra \n",
      "RT  King Oliver's Band 1931 \n",
      "RT  Bennie Moten's Radio Orchestra \n",
      "RT  Buffalo SpringfieldのMr. Soul  #NowPlaying\n",
      "RT  Daddy Dewdrop / Chick-A-Boom (Don't Ya Jes' Love It) (1971 US #9) Kenta's \n",
      "RT  Saturday Night Flow - yeah LAST Saturday night! Tonight I’m stuck in the crib helping a certain college student with 5 P…\n",
      "RT  . celebrates the legacy of Blue Note Records from our founding in 1939 to the vibrant sounds of today with the…\n",
      "RT  😢😰 \n",
      "Diz and Bird. left, Max.  \n",
      "RT  There is no remedy for love but to love more. Henry David Thoreau\n",
      "RT  Beck / Up All Night (2017) Kenta's  on twitter!\n",
      "RT  『アマル・ハヤーティ』(1965年／昭和40年) نادر : حفلة أمل حياتى لأم كلثوم كامله\n",
      "RT  Happy easter ! Have a blessed day everyone 🌻🐣 \n",
      "RT  Happiness does not lie in happiness, but in the achievement of it. Fedor Dostoyevsky\n",
      "RT  Jimmie Rodgers / Why Should I Be Lonely? (1930) Kenta's  on twitter!\n",
      "RT  \"BUFFALO\" released #OnThisDay in 2007.  This live 2CD release was recorded on Oct 25, 1980 at the Buffalo Memorial Auditorium in…\n",
      "RT  Mmmmm chocolate... 🍫\n",
      "Apple Music Playlist 2018.04.01 \n",
      "3578166252\n",
      "133684052\n",
      "63299591\n",
      "93196638\n",
      "いいね。RT  Bob Brookmeyer Quintet - Sometime Ago  #nowplaying #jazz\n",
      "RT  Bob Brookmeyer Quintet - Sometime Ago  #nowplaying #jazz\n",
      "いいね。RT  Freddie Hubbard - I Remember Clifford  #nowplaying #jazz\n",
      "RT  Freddie Hubbard - I Remember Clifford  #nowplaying #jazz\n",
      "豆乳を投入(=ﾟωﾟ)ﾉ。RT  豆乳を投入(=ﾟωﾟ)ﾉ　#豆乳を投入\n",
      "RT  Kehlani,  and  are just some of the artists  sees as the next generation of history makers. #Bl…\n",
      "RT  Happy birthday, Marvin Gaye. Got to give it up for the Prince of Soul 🙌 \n"
     ]
    },
    {
     "ename": "LangDetectException",
     "evalue": "No features in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30e4ecd0cdd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-6e02b00a1ec0>\u001b[0m in \u001b[0;36mfile_iterator\u001b[0;34m(aim_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mraw_data_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maim_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-c73efec7c0e5>\u001b[0m in \u001b[0;36mraw_data_collect\u001b[0;34m(rawdata, collection)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# check whether tweet is japanese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ja\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#lang = detect(tweet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m#print(lang)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/langdetect/detector_factory.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         '''\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36mget_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36m_detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLangDetectException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCantDetectError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'No features in text.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanglist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLangDetectException\u001b[0m: No features in text."
     ]
    }
   ],
   "source": [
    "file_iterator(\"raw2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
